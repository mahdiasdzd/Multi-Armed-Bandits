# Multi-Armed-Bandits-
Multi-Stage-Multi-Armed Bandits (MAB) are a class of reinforcement learning problems where an agent tries to maximize its cumulative reward by sequentially selecting actions from multiple options (arms) and observing the rewards associated with those actions.

In a Multi-Stage Multi-Armed Bandits model, the environment or the problem faced by the agent evolves over multiple stages or time periods. At each stage, the agent selects an action (arm) based on its current knowledge or belief about the rewards associated with each action. As the agent interacts with the environment, it learns more about the rewards of each action and can adapt its strategy accordingly.

These models are particularly useful in dynamic decision-making problems where the underlying parameters or conditions change over time. They find applications in various fields such as online advertising, clinical trials, resource allocation, and network routing, among others.

model stages:
stage 1 - building agent arms
stage 2 - test agent arms
stage 3 - invest agent arms

